{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "949 samples will be used as training data.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, r2_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import math\n",
    "\n",
    "#\n",
    "# read data (as a pd.DataFrame)\n",
    "#\n",
    "train_features = pd.read_csv('data/train_features.csv')\n",
    "train_labels = pd.read_csv('data/train_labels.csv')\n",
    "test_features = pd.read_csv('data/test_features.csv')\n",
    "\n",
    "\n",
    "# Split train data into test data for internal scoring (0.7 means 70% training data/30% test data)\n",
    "# Problem: The split happens sequentially and not randomly, eg. last rows are always testing data \n",
    "train_test_split_ratio = 0.05\n",
    "\n",
    "max_samples = train_labels.shape[0]\n",
    "split_data_row_index = math.floor(train_test_split_ratio*max_samples)\n",
    "print(split_data_row_index, 'samples will be used as training data.')\n",
    "\n",
    "train_X = train_features[0:split_data_row_index*12]\n",
    "train_y = train_labels[0:split_data_row_index]\n",
    "\n",
    "test_X = train_features[(split_data_row_index+1)*12:max_samples*12]\n",
    "test_y = train_labels[split_data_row_index+1:max_samples]\n",
    "\n",
    "medical_tests = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', 'LABEL_Lactate',\n",
    "                 'LABEL_TroponinI', 'LABEL_SaO2', 'LABEL_Bilirubin_direct',\n",
    "                 'LABEL_EtCO2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start imputing NaN values\n",
      "Finished imputing NaN values\n"
     ]
    }
   ],
   "source": [
    "# Missing Features / Imputation of NaN values\n",
    "\n",
    "# TODO: Idea: Use mean per patient\n",
    "# TODO: Idea: Use mean per age group\n",
    "\n",
    "# 'mean'          = mean of column\n",
    "# 'zero'          = 0\n",
    "# 'median'        = median of column\n",
    "# 'most-frequent' = smallest most frequent value\n",
    "\n",
    "selected_imputation_strategy = 'mean'\n",
    "\n",
    "print(\"Start imputing NaN values\")\n",
    "\n",
    "if selected_imputation_strategy == 'mean':\n",
    "    imputeMean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    train_X_imputed = pd.DataFrame(imputeMean.fit_transform(train_X), columns=train_X.columns)\n",
    "    test_X_imputed = pd.DataFrame(imputeMean.fit_transform(test_X), columns=test_X.columns)\n",
    "\n",
    "elif selected_imputation_strategy == 'zero':\n",
    "    imputeZero = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    train_X_imputed = pd.DataFrame(imputeZero.fit_transform(train_X), columns=train_X.columns)\n",
    "    test_X_imputed = pd.DataFrame(imputeZero.fit_transform(test_X), columns=test_X.columns)\n",
    "\n",
    "elif selected_imputation_strategy == 'median':\n",
    "    imputeMedian = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    train_X_imputed = pd.DataFrame(imputeMedian.fit_transform(train_X), columns=train_X.columns)\n",
    "    test_X_imputed = pd.DataFrame(imputeMedian.fit_transform(test_X), columns=test_X.columns)\n",
    "\n",
    "elif selected_imputation_strategy == 'most-frequent':\n",
    "    imputeMostFrequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    train_X_imputed = pd.DataFrame(imputeMostFrequent.fit_transform(train_X), columns=train_X.columns)\n",
    "    test_X_imputed = pd.DataFrame(imputeMostFrequent.fit_transform(test_X), columns=test_X.columns)\n",
    "else:\n",
    "    print('Imputation strategy is not selected.')\n",
    "\n",
    "print(\"Finished imputing NaN values\")\n",
    "\n",
    "    \n",
    "# Example using add_indicator = True for SimpleImputer\n",
    "# imputeMean = SimpleImputer(missing_values=np.nan, strategy='mean', add_indicator=add_indicator)\n",
    "# train_X_imputed = pd.DataFrame(imputeMean.fit_transform(train_X), columns=train_X.columns.append('imputed_' + train_X.columns[train_X.isna().sum() > 0]))\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Filter out age/time columns\n",
    "\n",
    "\n",
    "\n",
    "# Fix imbalanced classification data\n",
    "# TODO: Add balancing logic\n",
    "\n",
    "\n",
    "\n",
    "# Reshape patient data to single row\n",
    "train_X_flat = train_X_imputed.set_index('pid').groupby(level=0) \\\n",
    "    .apply(lambda df: df.reset_index(drop=True)) \\\n",
    "    .unstack().sort_index(axis=1, level=1)\n",
    "train_X_flat.columns = ['{}{}'.format(x[0], int(x[1]) + 1) for x in train_X_flat.columns]\n",
    "\n",
    "test_X_flat = test_X_imputed.set_index('pid').groupby(level=0) \\\n",
    "    .apply(lambda df: df.reset_index(drop=True)) \\\n",
    "    .unstack().sort_index(axis=1, level=1)\n",
    "test_X_flat.columns = ['{}{}'.format(x[0], int(x[1]) + 1) for x in test_X_flat.columns]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start SVM fitting for LABEL_BaseExcess\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-b0deec622beb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m#probabilities = clf.predict_proba(X)  # values between [0,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    269\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Task 1: Medical tests \n",
    "#  - SVC parameters to tune systematically\n",
    "#       kernel functions, C value, decision_function_shape\n",
    "#       class weight = can handle unbalanced classification data,\n",
    "#       (random_state (seed))\n",
    "\n",
    "\n",
    "# Train classifiers to predict ordered medical tests\n",
    "X = train_X_flat\n",
    "medical_test_scores = []\n",
    "\n",
    "for medical_test in medical_tests:\n",
    "    print(\"start SVM fitting for \" + medical_test)\n",
    "    y = train_y[medical_test]\n",
    "    y_test = test_y[medical_test]\n",
    "    clf = svm.SVC(kernel='rbf', cache_size=5000)\n",
    "    clf.probability = True\n",
    "    clf.fit(X, y)\n",
    "    #probabilities = clf.predict_proba(X)  # values between [0,1]\n",
    "\n",
    "    score = clf.score(test_X_flat, y_test)\n",
    "    auc_score = roc_auc_score(y_test, clf.decision_function(test_X_flat))\n",
    "    medical_test_scores.append([score, auc_score])\n",
    "\n",
    "for i, test in enumerate(medical_tests):\n",
    "    print(\"\\n\" + test + \"\\n average accuracy: \" + str(medical_test_scores[i][0]) +\n",
    "          \"\\n roc_auc score: \" + str(medical_test_scores[i][1]))\n",
    "\n",
    "task1_score = np.mean(np.array(medical_test_scores)[:, 1])\n",
    "print(\"Mean auc score: \", task1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Train classifier to predict sepsis event\n",
    "print(\"start svm fitting for sepsis prediction\")\n",
    "X = train_X_flat\n",
    "y = train_y['LABEL_Sepsis']\n",
    "y_test = test_y['LABEL_Sepsis']\n",
    "clf = svm.SVC(kernel='linear', cache_size=1000)\n",
    "clf.fit(X, y)\n",
    "print(\"\\nSepsis prediction\\n average accuracy: \" + str(clf.score(test_X_flat, y_test)) +\n",
    "      \"\\n roc_auc score: \" + str(roc_auc_score(y_test, clf.decision_function(test_X_flat))))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Train regressor to predict mean value of vital signs\n",
    "print(\"\\nstart linear fitting for vital signs\")\n",
    "X = train_X_flat\n",
    "y = train_y[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]\n",
    "y_test = test_y[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]\n",
    "reg = MultiOutputRegressor(linear_model.LinearRegression())  # lots of parameters that could be set here\n",
    "reg.fit(X, y)\n",
    "print(\"\\nVital signs prediction\\n R2 score: \" + str(r2_score(reg.predict(test_X_flat), y_test)))\n",
    "\n",
    "# # Evaluate strategies\n",
    "# results = list()\n",
    "# strategies = ['mean', 'median', 'most_frequent', 'constant']\n",
    "#for s in strategies:\n",
    "#    # create the modeling pipeline\n",
    "#    pipeline = Pipeline(steps=[('i', SimpleImputer(strategy=s)), ('m', RandomForestClassifier())]) # Replace Classifier by model\n",
    "#    # evaluate the model\n",
    "#    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=42)\n",
    "#    scores = cross_val_score(pipeline, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "#    # store results\n",
    "#    results.append(scores)\n",
    "#    print('>%s %.3f (%.3f)' % (s, np.mean(scores), np.std(scores)))\n",
    "\n",
    "\n",
    "# plot model performance for comparison\n",
    "# plt.boxplot(results, labels=strategies, showmeans=True)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1_score = np.mean(np.array(medical_test_scores)[:, 1])\n",
    "task2_score = roc_auc_score(test_y['LABEL_Sepsis'], clf.decision_function(test_X_flat))\n",
    "task3_score = np.mean([0.5 + 0.5 * np.maximum(0, r2_score(reg.predict(test_X_flat), test_y[['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']]))])\n",
    "\n",
    "total_score = np.mean([task1_score, task2_score, task3_score])\n",
    "\n",
    "print(\"\\nScores:\\n\\nTask 1: \" + str(task1_score) + \"\\nTask 2: \" + str(task2_score) + \"\\nTask 3: \" + str(task3_score) + \"\\n\\nTotal Score: \" + str(total_score))\n",
    "print(\"\\nBaseline: \" + str(0.713853457215))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
