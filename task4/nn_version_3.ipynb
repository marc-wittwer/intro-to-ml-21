{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "# from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "# import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_epochs = 30  # each epoch is one pass over the whole dataset\n",
    "batch_size = 512  # how many samples per training step (32,64,128)\n",
    "num_workers = 7  # how many CPU cores to use\n",
    "\n",
    "n_features = 1000 # How many features per image\n",
    "\n",
    "# Specify some file names\n",
    "img_features_file = \"image_features_mobileNetv3small.csv\"\n",
    "train_triplets_file = \"train_triplets.txt\" #\"train_triplets.txt\"\n",
    "test_triplets_file = \"test_triplets.txt\" #\"test_triplets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class FoodTriplets(Dataset):\n",
    "    \"\"\"\n",
    "    Class to load food triplets. Individual items consist of:\n",
    "     - x: concatenated image features of a triplet (ABC)\n",
    "     - y: corresponding label (1: B is more similar, 0: C is more similar, None: no label)\n",
    "    \"\"\"\n",
    "    def __init__(self, features_file, triplets_file, is_labelled_data=False):\n",
    "        print(\"initializing \" + str(triplets_file) + \" dataset...\")\n",
    "        self.img_features = pd.read_csv(\"data/\" + features_file, header=None, index_col=0)\n",
    "        self.triplets = pd.read_csv(\"data/\" + triplets_file, sep=\" \", header=None).to_numpy()\n",
    "        self.is_labelled_data = is_labelled_data\n",
    "        self.labels = None\n",
    "\n",
    "        if self.is_labelled_data:\n",
    "            # For each triplet ABC add a triplet ACB\n",
    "            # Also add corresponding labels\n",
    "            dim = self.triplets.shape\n",
    "            extended_triplets = np.zeros((2*dim[0], dim[1]), dtype=np.int32)\n",
    "            self.labels = np.zeros(2*dim[0], dtype=bool)\n",
    "            idx = 0\n",
    "            for triplet in self.triplets:\n",
    "                extended_triplets[idx, :] = triplet\n",
    "                extended_triplets[idx + 1, :] = [triplet[0], triplet[2], triplet[1]]\n",
    "                self.labels[idx] = 1  # label at idx+1 is already initialized to 0\n",
    "                idx += 2\n",
    "\n",
    "            self.triplets = extended_triplets\n",
    "\n",
    "        print(\"done\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets[idx]\n",
    "        a, b, c = triplet[0], triplet[1], triplet[2]\n",
    "        a_features = self.img_features.loc[[a]].to_numpy(dtype=np.float32)\n",
    "        b_features = self.img_features.loc[[b]].to_numpy(dtype=np.float32)\n",
    "        c_features = self.img_features.loc[[c]].to_numpy(dtype=np.float32)\n",
    "        features = np.squeeze(np.concatenate((a_features, b_features, c_features), axis=1))\n",
    "        label = 0  # dummy label\n",
    "        if self.is_labelled_data:\n",
    "            label = np.array([self.labels[idx]])\n",
    "        return {\"x\": features, \"y\": label}\n",
    "\n",
    "def get_model(device):\n",
    "    return SimpleNetwork().to(device)\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        nin = 3*n_features\n",
    "        n1 = 2*n_features\n",
    "        n2 = n_features\n",
    "        n3 = int(n_features/2)\n",
    "        n4 = int(n_features/4)\n",
    "        n5 = int(n_features/8)\n",
    "        nout = 1\n",
    "\n",
    "        p_dropout1 = 0.3\n",
    "        p_dropout2 = 0.5\n",
    "        p_dropout3 = 0.5\n",
    "        p_dropout4 = 0.5\n",
    "        p_dropout5 = 0.2\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=nin, out_features=n1),\n",
    "            nn.BatchNorm1d(n1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_dropout1, inplace=False),\n",
    "            nn.Linear(in_features=n1, out_features=n2),\n",
    "            nn.BatchNorm1d(n2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_dropout2, inplace=False),\n",
    "            nn.Linear(in_features=n2, out_features=n3),\n",
    "            nn.BatchNorm1d(n3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_dropout3, inplace=False),\n",
    "            nn.Linear(in_features=n3, out_features=n4),\n",
    "            nn.BatchNorm1d(n4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_dropout4, inplace=False),\n",
    "            nn.Linear(in_features=n4, out_features=n5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(n5),\n",
    "            nn.Dropout(p=p_dropout5, inplace=False),\n",
    "            nn.Linear(in_features=n5, out_features=nout),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing train_triplets.txt dataset...\n",
      "done\n",
      "initializing test_triplets.txt dataset...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# initialize datasets\n",
    "train_data = FoodTriplets(img_features_file, train_triplets_file, is_labelled_data=True)\n",
    "test_data = FoodTriplets(img_features_file, test_triplets_file, is_labelled_data=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Split train set into train and test set to assess accuracy on unused set\n",
    "l_train = len(train_data)\n",
    "val_size = int(0 * l_train + 1)\n",
    "indices = list(range(l_train))\n",
    "np.random.shuffle(indices)\n",
    "val_indices, t_indices = indices[:val_size], indices[val_size:]\n",
    "\n",
    "\n",
    "train_trainloader = DataLoader(torch.utils.data.Subset(train_data, t_indices), batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "train_testloader = DataLoader(torch.utils.data.Subset(train_data, val_indices), batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def experiment(num_epochs, trainloader, device, model, optimizer, scheduler):\n",
    "    train_results = {}\n",
    "    test_results = {}\n",
    "    # Initial test error\n",
    "    loss, acc, time = test(device, model)\n",
    "    print(f'Upon initialization. [Test] \\t Time {time.avg:.2f} \\\n",
    "            Loss {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "    test_results[0] = (loss, acc, time)\n",
    "\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        loss, acc, time = train(trainloader, device, model, optimizer, scheduler)\n",
    "        print(f'Epoch {epoch}. [Train] \\t Time {time.sum:.2f} Loss \\\n",
    "                {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "        train_results[epoch] = (loss.avg, acc.avg, time.avg)\n",
    "\n",
    "        if not (epoch % 2):\n",
    "          loss, acc, time = test(device, model)\n",
    "          print(f'Epoch {epoch}. [Test] \\t Time {time.sum:.2f} Loss \\\n",
    "                {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "          test_results[epoch] = (loss.avg, acc.avg, time.avg)\n",
    "\n",
    "def train(trainloader, device, model, optimizer, scheduler):\n",
    "    time_ = AverageMeter()\n",
    "    loss_ = AverageMeter()\n",
    "    acc_ = AverageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for i, data, in enumerate(trainloader, 1):\n",
    "        # Accounting\n",
    "        end = time.time()\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[\"x\"].float()\n",
    "        labels = data[\"y\"].float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bs = inputs.size(0)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()  # all the tensors have .grad attribute\n",
    "        # forward propagation\n",
    "        logits = model(inputs) # forward propagation\n",
    "        loss = criterion(logits, labels) # computing the loss for predictions\n",
    "        # Backward propagation\n",
    "        loss.backward() # backpropgation\n",
    "        # Optimization step.\n",
    "        optimizer.step() # applying an optimization step\n",
    "\n",
    "        # Accounting\n",
    "        acc = ((torch.round(logits) == labels).sum().float() / bs).float()\n",
    "        loss_.update(loss.mean().item(), bs)\n",
    "        acc_.update(acc.item(), bs)\n",
    "        time_.update(time.time() - end)\n",
    "\n",
    "    scheduler.step()\n",
    "    return loss_, acc_, time_\n",
    "\n",
    "def test(device, model):\n",
    "    time_ = AverageMeter()\n",
    "    loss_ = AverageMeter()\n",
    "    acc_ = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for i, data, in enumerate(train_testloader, 1):\n",
    "        # Accounting\n",
    "        end = time.time()\n",
    "\n",
    "        inputs = data[\"x\"].float()\n",
    "        labels = data[\"y\"].float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        bs = inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            acc = ((torch.round(logits) == labels).sum().float() / bs).float()\n",
    "\n",
    "            # Accounting\n",
    "            loss_.update(loss.mean().item(), bs)\n",
    "            acc_.update(acc.mean().item(), bs)\n",
    "            time_.update(time.time() - end)\n",
    "\n",
    "    return loss_, acc_, time_\n",
    "\n",
    "class AverageMeter():\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = get_model(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.01, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon initialization. [Test] \t Time 0.01             Loss 0.72 \t Accuracy 0.00\n",
      "Epoch 1. [Train] \t Time 15.14 Loss                 0.62 \t Accuracy 0.64\n",
      "Epoch 2. [Train] \t Time 15.24 Loss                 0.54 \t Accuracy 0.72\n",
      "Epoch 2. [Test] \t Time 0.00 Loss                 0.31 \t Accuracy 1.00\n",
      "Epoch 3. [Train] \t Time 15.33 Loss                 0.50 \t Accuracy 0.75\n",
      "Epoch 4. [Train] \t Time 15.34 Loss                 0.46 \t Accuracy 0.78\n",
      "Epoch 4. [Test] \t Time 0.00 Loss                 0.64 \t Accuracy 1.00\n",
      "Epoch 5. [Train] \t Time 15.39 Loss                 0.42 \t Accuracy 0.81\n",
      "Epoch 6. [Train] \t Time 15.44 Loss                 0.37 \t Accuracy 0.84\n",
      "Epoch 6. [Test] \t Time 0.00 Loss                 0.46 \t Accuracy 1.00\n",
      "Epoch 7. [Train] \t Time 29.15 Loss                 0.32 \t Accuracy 0.86\n",
      "Epoch 8. [Train] \t Time 29.11 Loss                 0.28 \t Accuracy 0.88\n",
      "Epoch 8. [Test] \t Time 0.00 Loss                 0.07 \t Accuracy 1.00\n",
      "Epoch 9. [Train] \t Time 29.06 Loss                 0.24 \t Accuracy 0.90\n",
      "Epoch 10. [Train] \t Time 29.10 Loss                 0.21 \t Accuracy 0.91\n",
      "Epoch 10. [Test] \t Time 0.00 Loss                 0.26 \t Accuracy 1.00\n",
      "Epoch 11. [Train] \t Time 29.22 Loss                 0.12 \t Accuracy 0.95\n",
      "Epoch 12. [Train] \t Time 29.13 Loss                 0.09 \t Accuracy 0.97\n",
      "Epoch 12. [Test] \t Time 0.00 Loss                 0.01 \t Accuracy 1.00\n",
      "Epoch 13. [Train] \t Time 29.21 Loss                 0.07 \t Accuracy 0.97\n",
      "Epoch 14. [Train] \t Time 29.53 Loss                 0.06 \t Accuracy 0.98\n",
      "Epoch 14. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 15. [Train] \t Time 29.56 Loss                 0.05 \t Accuracy 0.98\n",
      "Epoch 16. [Train] \t Time 29.35 Loss                 0.05 \t Accuracy 0.98\n",
      "Epoch 16. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 17. [Train] \t Time 29.18 Loss                 0.04 \t Accuracy 0.98\n",
      "Epoch 18. [Train] \t Time 29.43 Loss                 0.04 \t Accuracy 0.99\n",
      "Epoch 18. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 19. [Train] \t Time 29.12 Loss                 0.04 \t Accuracy 0.99\n",
      "Epoch 20. [Train] \t Time 28.68 Loss                 0.03 \t Accuracy 0.99\n",
      "Epoch 20. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 21. [Train] \t Time 29.15 Loss                 0.03 \t Accuracy 0.99\n",
      "Epoch 22. [Train] \t Time 29.39 Loss                 0.03 \t Accuracy 0.99\n",
      "Epoch 22. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 23. [Train] \t Time 29.37 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 24. [Train] \t Time 29.38 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 24. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 25. [Train] \t Time 29.41 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 26. [Train] \t Time 29.18 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 26. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 27. [Train] \t Time 29.53 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 28. [Train] \t Time 29.22 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 28. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 29. [Train] \t Time 29.31 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 30. [Train] \t Time 29.30 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 30. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 31. [Train] \t Time 29.46 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 32. [Train] \t Time 29.36 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 32. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 33. [Train] \t Time 29.46 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 34. [Train] \t Time 29.33 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 34. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 35. [Train] \t Time 29.34 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 36. [Train] \t Time 29.06 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 36. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 37. [Train] \t Time 29.58 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 38. [Train] \t Time 29.23 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 38. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 39. [Train] \t Time 29.37 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 40. [Train] \t Time 29.28 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 40. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 41. [Train] \t Time 29.46 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 42. [Train] \t Time 29.40 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 42. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 43. [Train] \t Time 29.43 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 44. [Train] \t Time 29.21 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 44. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 45. [Train] \t Time 29.26 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 46. [Train] \t Time 29.66 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 46. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 47. [Train] \t Time 29.24 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 48. [Train] \t Time 29.13 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 48. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n",
      "Epoch 49. [Train] \t Time 29.05 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 50. [Train] \t Time 29.11 Loss                 0.02 \t Accuracy 0.99\n",
      "Epoch 50. [Test] \t Time 0.00 Loss                 0.00 \t Accuracy 1.00\n"
     ]
    }
   ],
   "source": [
    "experiment(num_epochs=num_epochs,\n",
    "           trainloader=train_trainloader,\n",
    "           device=device,\n",
    "           model=model,\n",
    "           optimizer=optimizer,\n",
    "           scheduler=lr_scheduler)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on test_data...\n",
      "Predicted: 0/59544, Time elapsed: 00:00:00.18\n",
      "Predicted: 1000/59544, Time elapsed: 00:00:02.13\n",
      "Predicted: 2000/59544, Time elapsed: 00:00:03.88\n",
      "Predicted: 3000/59544, Time elapsed: 00:00:05.63\n",
      "Predicted: 4000/59544, Time elapsed: 00:00:07.35\n",
      "Predicted: 5000/59544, Time elapsed: 00:00:09.12\n",
      "Predicted: 6000/59544, Time elapsed: 00:00:10.88\n",
      "Predicted: 7000/59544, Time elapsed: 00:00:12.66\n",
      "Predicted: 8000/59544, Time elapsed: 00:00:14.70\n",
      "Predicted: 9000/59544, Time elapsed: 00:00:16.90\n",
      "Predicted: 10000/59544, Time elapsed: 00:00:18.69\n",
      "Predicted: 11000/59544, Time elapsed: 00:00:20.53\n",
      "Predicted: 12000/59544, Time elapsed: 00:00:22.49\n",
      "Predicted: 13000/59544, Time elapsed: 00:00:24.32\n",
      "Predicted: 14000/59544, Time elapsed: 00:00:26.23\n",
      "Predicted: 15000/59544, Time elapsed: 00:00:28.08\n",
      "Predicted: 16000/59544, Time elapsed: 00:00:29.83\n",
      "Predicted: 17000/59544, Time elapsed: 00:00:31.75\n",
      "Predicted: 18000/59544, Time elapsed: 00:00:33.64\n",
      "Predicted: 19000/59544, Time elapsed: 00:00:35.39\n",
      "Predicted: 20000/59544, Time elapsed: 00:00:37.18\n",
      "Predicted: 21000/59544, Time elapsed: 00:00:38.93\n",
      "Predicted: 22000/59544, Time elapsed: 00:00:40.73\n",
      "Predicted: 23000/59544, Time elapsed: 00:00:42.52\n",
      "Predicted: 24000/59544, Time elapsed: 00:00:44.31\n",
      "Predicted: 25000/59544, Time elapsed: 00:00:46.10\n",
      "Predicted: 26000/59544, Time elapsed: 00:00:47.84\n",
      "Predicted: 27000/59544, Time elapsed: 00:00:49.58\n",
      "Predicted: 28000/59544, Time elapsed: 00:00:51.45\n",
      "Predicted: 29000/59544, Time elapsed: 00:00:53.47\n",
      "Predicted: 30000/59544, Time elapsed: 00:00:55.44\n",
      "Predicted: 31000/59544, Time elapsed: 00:00:57.72\n",
      "Predicted: 32000/59544, Time elapsed: 00:00:59.86\n",
      "Predicted: 33000/59544, Time elapsed: 00:01:01.82\n",
      "Predicted: 34000/59544, Time elapsed: 00:01:04.44\n",
      "Predicted: 35000/59544, Time elapsed: 00:01:06.54\n",
      "Predicted: 36000/59544, Time elapsed: 00:01:08.75\n",
      "Predicted: 37000/59544, Time elapsed: 00:01:10.83\n",
      "Predicted: 38000/59544, Time elapsed: 00:01:13.03\n",
      "Predicted: 39000/59544, Time elapsed: 00:01:15.04\n",
      "Predicted: 40000/59544, Time elapsed: 00:01:17.31\n",
      "Predicted: 41000/59544, Time elapsed: 00:01:19.41\n",
      "Predicted: 42000/59544, Time elapsed: 00:01:21.49\n",
      "Predicted: 43000/59544, Time elapsed: 00:01:23.52\n",
      "Predicted: 44000/59544, Time elapsed: 00:01:25.40\n",
      "Predicted: 45000/59544, Time elapsed: 00:01:27.25\n",
      "Predicted: 46000/59544, Time elapsed: 00:01:29.10\n",
      "Predicted: 47000/59544, Time elapsed: 00:01:31.01\n",
      "Predicted: 48000/59544, Time elapsed: 00:01:33.53\n",
      "Predicted: 49000/59544, Time elapsed: 00:01:35.49\n",
      "Predicted: 50000/59544, Time elapsed: 00:01:37.45\n",
      "Predicted: 51000/59544, Time elapsed: 00:01:39.32\n",
      "Predicted: 52000/59544, Time elapsed: 00:01:41.24\n",
      "Predicted: 53000/59544, Time elapsed: 00:01:43.32\n",
      "Predicted: 54000/59544, Time elapsed: 00:01:45.71\n",
      "Predicted: 55000/59544, Time elapsed: 00:01:47.73\n",
      "Predicted: 56000/59544, Time elapsed: 00:01:50.06\n",
      "Predicted: 57000/59544, Time elapsed: 00:01:51.96\n",
      "Predicted: 58000/59544, Time elapsed: 00:01:53.89\n",
      "Predicted: 59000/59544, Time elapsed: 00:01:55.79\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "def timer(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(minutes), seconds)\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# predict on test_data\n",
    "# model_pred = nn.Sequential(model, nn.Sigmoid())  # add sigmoid to get output in [0,1]\n",
    "predictions = np.zeros(len(test_data))\n",
    "print(\"predicting on test_data...\")\n",
    "l_test = len(test_data)\n",
    "start_t = time.time()\n",
    "\n",
    "# Set model to evaluating mode\n",
    "model.eval()\n",
    "# model.to(device)\n",
    "# model_pred.eval()\n",
    "# model_pred.to(device)\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    x = data[\"x\"].float()\n",
    "    \n",
    "    x = x.to(device)\n",
    "    predictions[i] = model(x)\n",
    "    # predictions[i] = model_pred(x)\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicted: {i}/{l_test}, Time elapsed: {timer(start_t, time.time())}\")\n",
    "        \n",
    "        \n",
    "# predictions_INT = pd.DataFrame(predictions).astype(int)\n",
    "predictions_DF = pd.DataFrame(predictions)\n",
    "predictions_rounded = predictions_DF.round(0)\n",
    "\n",
    "# print(\"saving predictions...\")\n",
    "# predictions_INT.to_csv('data/predictions.csv', index=False, header=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving predictions...\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": "      0\n0   1.0\n1   0.0\n2   0.0\n3   1.0\n4   1.0\n..  ...\n95  1.0\n96  1.0\n97  0.0\n98  1.0\n99  0.0\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# res = pd.DataFrame(predictions_rounded).astype(int)\n",
    "res = pd.DataFrame(predictions_rounded)\n",
    "print(\"saving predictions...\")\n",
    "res.to_csv('data/predictions.csv', index=False, header=False)\n",
    "print(\"done\")\n",
    "\n",
    "res.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"model\").mkdir(parents=True, exist_ok=True)  # create folder if necessary\n",
    "torch.save(model.state_dict(), \"model/params_6_layers_mobileNetV3small_v2\")\n",
    "# load: model.load_state_dict(torch.load(\"model/params\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-20844a55",
   "language": "python",
   "display_name": "PyCharm (intro-to-ml-21)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}