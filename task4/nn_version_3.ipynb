{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "num_epochs = 100  # each epoch is one pass over the whole dataset\n",
    "batch_size = 32  # how many samples per training step (32,64,128)\n",
    "num_workers = 7  # how many CPU cores to use\n",
    "\n",
    "n_features = 4096 # How many features per image\n",
    "\n",
    "# Specify some file names\n",
    "img_features_file = \"train_image_features_vgg16bn.csv\"\n",
    "train_triplets_file = \"train_triplets.txt\" #\"train_triplets.txt\"\n",
    "test_triplets_file = \"test_triplets.txt\" #\"test_triplets.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class FoodTriplets(Dataset):\n",
    "    \"\"\"\n",
    "    Class to load food triplets. Individual items consist of:\n",
    "     - x: concatenated image features of a triplet (ABC)\n",
    "     - y: corresponding label (1: B is more similar, 0: C is more similar, None: no label)\n",
    "    \"\"\"\n",
    "    def __init__(self, features_file, triplets_file, is_labelled_data=False):\n",
    "        print(\"initializing \" + str(triplets_file) + \" dataset...\")\n",
    "        self.img_features = pd.read_csv(\"data/\" + features_file, header=None, index_col=0)\n",
    "        self.triplets = pd.read_csv(\"data/\" + triplets_file, sep=\" \", header=None).to_numpy()\n",
    "        self.is_labelled_data = is_labelled_data\n",
    "        self.labels = None\n",
    "\n",
    "        if self.is_labelled_data:\n",
    "            # For each triplet ABC add a triplet ACB\n",
    "            # Also add corresponding labels\n",
    "            dim = self.triplets.shape\n",
    "            extended_triplets = np.zeros((2*dim[0], dim[1]), dtype=np.int32)\n",
    "            self.labels = np.zeros(2*dim[0], dtype=np.bool)\n",
    "            idx = 0\n",
    "            for triplet in self.triplets:\n",
    "                extended_triplets[idx, :] = triplet\n",
    "                extended_triplets[idx + 1, :] = [triplet[0], triplet[2], triplet[1]]\n",
    "                self.labels[idx] = 1  # label at idx+1 is already initialized to 0\n",
    "                idx += 2\n",
    "\n",
    "            self.triplets = extended_triplets\n",
    "\n",
    "        print(\"done\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets[idx]\n",
    "        a, b, c = triplet[0], triplet[1], triplet[2]\n",
    "        a_features = self.img_features.loc[[a]].to_numpy(dtype=np.float32)\n",
    "        b_features = self.img_features.loc[[b]].to_numpy(dtype=np.float32)\n",
    "        c_features = self.img_features.loc[[c]].to_numpy(dtype=np.float32)\n",
    "        features = np.concatenate((a_features, b_features, c_features), axis=1)\n",
    "        label = 0  # dummy label\n",
    "        if self.is_labelled_data:\n",
    "            label = np.array([[self.labels[idx]]])\n",
    "        return {\"x\": features, \"y\": label}\n",
    "\n",
    "def get_model(device):\n",
    "    return SimpleNetwork().to(device)\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        nin = 3*n_features\n",
    "        n1 = int(3*n_features/2)\n",
    "        n2 = int(3*n_features/4)\n",
    "        n3 = int(3*n_features/8)\n",
    "        n4 = 500\n",
    "        n5 = 250\n",
    "        nout = 1\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=nin, out_features=n1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(in_features=n1, out_features=n2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(in_features=n2, out_features=n3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(in_features=n3, out_features=n4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # nn.Dropout(p=0.2, inplace=False),\n",
    "            nn.Linear(in_features=n4, out_features=n5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=n5, out_features=nout),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.classifier(x)\n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing train_triplets.txt dataset...\n",
      "done\n",
      "initializing test_triplets.txt dataset...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# initialize datasets\n",
    "train_data = FoodTriplets(img_features_file, train_triplets_file, is_labelled_data=True)\n",
    "test_data = FoodTriplets(img_features_file, test_triplets_file, is_labelled_data=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Initialize dataloaders\n",
    "# Split train set into train and test set to assess accuracy on unused set\n",
    "train_trainloader = DataLoader(Subset(train_data, range(0, int(train_data.__len__()*0.9)*0+10000)), batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "train_testloader = DataLoader(Subset(train_data, range(int(train_data.__len__()*0.9)*0+1*0+10001, int(train_data.__len__())*0+11000)), batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=None, shuffle=False, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def experiment(num_epochs, trainloader, device, model, optimizer):\n",
    "    train_results = {}\n",
    "    test_results = {}\n",
    "    # Initial test error\n",
    "    loss, acc, time = test(device, model)\n",
    "    print(f'Upon initialization. [Test] \\t Time {time.avg:.2f} \\\n",
    "            Loss {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "    test_results[0] = (loss, acc, time)\n",
    "\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        loss, acc, time = train(trainloader, device, model, optimizer)\n",
    "        print(f'Epoch {epoch}. [Train] \\t Time {time.sum:.2f} Loss \\\n",
    "                {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "        train_results[epoch] = (loss.avg, acc.avg, time.avg)\n",
    "\n",
    "        if not (epoch % 2):\n",
    "          loss, acc, time = test(device, model)\n",
    "          print(f'Epoch {epoch}. [Test] \\t Time {time.sum:.2f} Loss \\\n",
    "                {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
    "          test_results[epoch] = (loss.avg, acc.avg, time.avg)\n",
    "\n",
    "def train(trainloader, device, model, optimizer):\n",
    "    time_ = AverageMeter()\n",
    "    loss_ = AverageMeter()\n",
    "    acc_ = AverageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for i, data, in enumerate(trainloader, 1):\n",
    "        # Accounting\n",
    "        end = time.time()\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = data[\"x\"].float()\n",
    "        labels = data[\"y\"].float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        bs = inputs.size(0)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()  # all the tensors have .grad attribute\n",
    "        # forward propagation\n",
    "        logits = model(inputs) # forward propagation\n",
    "        loss = criterion(logits, labels) # computing the loss for predictions\n",
    "        # Backward propagation\n",
    "        loss.backward() # backpropgation\n",
    "        # Optimization step.\n",
    "        optimizer.step() # applying an optimization step\n",
    "\n",
    "        # Accounting\n",
    "        acc = ((torch.round(logits) == labels).sum().float() / bs).float()\n",
    "        loss_.update(loss.mean().item(), bs)\n",
    "        acc_.update(acc.item(), bs)\n",
    "        time_.update(time.time() - end)\n",
    "\n",
    "    return loss_, acc_, time_\n",
    "\n",
    "def test(device, model):\n",
    "    time_ = AverageMeter()\n",
    "    loss_ = AverageMeter()\n",
    "    acc_ = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for i, data, in enumerate(train_testloader, 1):\n",
    "        # Accounting\n",
    "        end = time.time()\n",
    "\n",
    "        inputs = data[\"x\"].float()\n",
    "        labels = data[\"y\"].float()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        bs = inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, labels)\n",
    "            acc = ((torch.round(logits) == labels).sum().float() / bs).float()\n",
    "\n",
    "            # Accounting\n",
    "            loss_.update(loss.mean().item(), bs)\n",
    "            acc_.update(acc.mean().item(), bs)\n",
    "            time_.update(time.time() - end)\n",
    "\n",
    "    return loss_, acc_, time_\n",
    "\n",
    "class AverageMeter():\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = get_model(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.01, nesterov=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upon initialization. [Test] \t Time 0.02             Loss 0.25 \t Accuracy 0.50\n",
      "Epoch 1. [Train] \t Time 48.68 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 2. [Train] \t Time 104.32 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 2. [Test] \t Time 2.40 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 3. [Train] \t Time 107.10 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 4. [Train] \t Time 105.37 Loss                 0.25 \t Accuracy 0.51\n",
      "Epoch 4. [Test] \t Time 2.40 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 5. [Train] \t Time 100.72 Loss                 0.25 \t Accuracy 0.52\n",
      "Epoch 6. [Train] \t Time 101.88 Loss                 0.25 \t Accuracy 0.52\n",
      "Epoch 6. [Test] \t Time 2.35 Loss                 0.25 \t Accuracy 0.50\n",
      "Epoch 7. [Train] \t Time 104.86 Loss                 0.25 \t Accuracy 0.53\n",
      "Epoch 8. [Train] \t Time 105.26 Loss                 0.25 \t Accuracy 0.53\n",
      "Epoch 8. [Test] \t Time 2.36 Loss                 0.25 \t Accuracy 0.55\n",
      "Epoch 9. [Train] \t Time 101.59 Loss                 0.25 \t Accuracy 0.54\n",
      "Epoch 10. [Train] \t Time 104.00 Loss                 0.25 \t Accuracy 0.55\n",
      "Epoch 10. [Test] \t Time 2.17 Loss                 0.26 \t Accuracy 0.50\n",
      "Epoch 11. [Train] \t Time 104.56 Loss                 0.24 \t Accuracy 0.56\n",
      "Epoch 12. [Train] \t Time 105.00 Loss                 0.24 \t Accuracy 0.56\n",
      "Epoch 12. [Test] \t Time 2.19 Loss                 0.25 \t Accuracy 0.55\n",
      "Epoch 13. [Train] \t Time 109.70 Loss                 0.24 \t Accuracy 0.58\n",
      "Epoch 14. [Train] \t Time 105.54 Loss                 0.24 \t Accuracy 0.58\n",
      "Epoch 14. [Test] \t Time 2.20 Loss                 0.24 \t Accuracy 0.55\n",
      "Epoch 15. [Train] \t Time 105.98 Loss                 0.24 \t Accuracy 0.58\n",
      "Epoch 16. [Train] \t Time 105.00 Loss                 0.24 \t Accuracy 0.60\n",
      "Epoch 16. [Test] \t Time 2.19 Loss                 0.26 \t Accuracy 0.51\n",
      "Epoch 17. [Train] \t Time 104.87 Loss                 0.24 \t Accuracy 0.60\n",
      "Epoch 18. [Train] \t Time 105.07 Loss                 0.24 \t Accuracy 0.61\n",
      "Epoch 18. [Test] \t Time 2.20 Loss                 0.25 \t Accuracy 0.51\n",
      "Epoch 19. [Train] \t Time 105.10 Loss                 0.23 \t Accuracy 0.62\n",
      "Epoch 20. [Train] \t Time 106.34 Loss                 0.23 \t Accuracy 0.62\n",
      "Epoch 20. [Test] \t Time 2.19 Loss                 0.25 \t Accuracy 0.55\n",
      "Epoch 21. [Train] \t Time 106.02 Loss                 0.23 \t Accuracy 0.64\n",
      "Epoch 22. [Train] \t Time 105.09 Loss                 0.23 \t Accuracy 0.64\n",
      "Epoch 22. [Test] \t Time 2.18 Loss                 0.28 \t Accuracy 0.50\n",
      "Epoch 23. [Train] \t Time 103.40 Loss                 0.22 \t Accuracy 0.64\n",
      "Epoch 24. [Train] \t Time 104.52 Loss                 0.22 \t Accuracy 0.64\n",
      "Epoch 24. [Test] \t Time 2.39 Loss                 0.26 \t Accuracy 0.53\n",
      "Epoch 25. [Train] \t Time 105.09 Loss                 0.22 \t Accuracy 0.64\n",
      "Epoch 26. [Train] \t Time 104.27 Loss                 0.21 \t Accuracy 0.66\n",
      "Epoch 26. [Test] \t Time 2.15 Loss                 0.26 \t Accuracy 0.51\n",
      "Epoch 27. [Train] \t Time 104.83 Loss                 0.21 \t Accuracy 0.66\n",
      "Epoch 28. [Train] \t Time 104.78 Loss                 0.21 \t Accuracy 0.68\n",
      "Epoch 28. [Test] \t Time 2.40 Loss                 0.26 \t Accuracy 0.52\n",
      "Epoch 29. [Train] \t Time 103.36 Loss                 0.21 \t Accuracy 0.67\n",
      "Epoch 30. [Train] \t Time 106.23 Loss                 0.20 \t Accuracy 0.69\n",
      "Epoch 30. [Test] \t Time 2.38 Loss                 0.27 \t Accuracy 0.53\n",
      "Epoch 31. [Train] \t Time 103.72 Loss                 0.20 \t Accuracy 0.70\n",
      "Epoch 32. [Train] \t Time 104.49 Loss                 0.19 \t Accuracy 0.71\n",
      "Epoch 32. [Test] \t Time 2.39 Loss                 0.25 \t Accuracy 0.57\n",
      "Epoch 33. [Train] \t Time 102.11 Loss                 0.19 \t Accuracy 0.71\n",
      "Epoch 34. [Train] \t Time 102.24 Loss                 0.19 \t Accuracy 0.71\n",
      "Epoch 34. [Test] \t Time 2.19 Loss                 0.27 \t Accuracy 0.55\n",
      "Epoch 35. [Train] \t Time 103.15 Loss                 0.19 \t Accuracy 0.72\n",
      "Epoch 36. [Train] \t Time 103.28 Loss                 0.18 \t Accuracy 0.72\n",
      "Epoch 36. [Test] \t Time 2.38 Loss                 0.32 \t Accuracy 0.55\n",
      "Epoch 37. [Train] \t Time 102.22 Loss                 0.18 \t Accuracy 0.73\n",
      "Epoch 38. [Train] \t Time 104.29 Loss                 0.18 \t Accuracy 0.74\n",
      "Epoch 38. [Test] \t Time 2.39 Loss                 0.25 \t Accuracy 0.56\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-06d5ea103bab>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m experiment(num_epochs=num_epochs,\n\u001B[0m\u001B[1;32m      2\u001B[0m            \u001B[0mtrainloader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtrain_trainloader\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m            \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m            \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m            optimizer=optimizer)\n",
      "\u001B[0;32m<ipython-input-5-1f6344fc47ff>\u001B[0m in \u001B[0;36mexperiment\u001B[0;34m(num_epochs, trainloader, device, model, optimizer)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m         \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0macc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrainloader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         print(f'Epoch {epoch}. [Train] \\t Time {time.sum:.2f} Loss \\\n\u001B[1;32m     14\u001B[0m                 {loss.avg:.2f} \\t Accuracy {acc.avg:.2f}')\n",
      "\u001B[0;32m<ipython-input-5-1f6344fc47ff>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(trainloader, device, model, optimizer)\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[0;31m# Accounting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0macc\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogits\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mloss_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0macc_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0macc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0mtime_\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mend\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "experiment(num_epochs=num_epochs,\n",
    "           trainloader=train_trainloader,\n",
    "           device=device,\n",
    "           model=model,\n",
    "           optimizer=optimizer)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(minutes), seconds)\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# predict on test_data\n",
    "# model_pred = nn.Sequential(model, nn.Sigmoid())  # add sigmoid to get output in [0,1]\n",
    "predictions = np.zeros(len(test_data))\n",
    "print(\"predicting on test_data...\")\n",
    "l_test = len(test_data)\n",
    "start_t = time.time()\n",
    "\n",
    "# Set model to evaluating mode\n",
    "model.eval()\n",
    "# model.to(device)\n",
    "# model_pred.eval()\n",
    "# model_pred.to(device)\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    x = data[\"x\"].float()\n",
    "    \n",
    "    x = x.to(device)\n",
    "    predictions[i] = model(x)\n",
    "    # predictions[i] = model_pred(x)\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicted: {i}/{l_test}, Time elapsed: {timer(start_t, time.time())}\")\n",
    "        \n",
    "        \n",
    "# predictions_INT = pd.DataFrame(predictions).astype(int)\n",
    "predictions_DF = pd.DataFrame(predictions)\n",
    "predictions_rounded = predictions_DF.round(0)\n",
    "\n",
    "# print(\"saving predictions...\")\n",
    "# predictions_INT.to_csv('data/predictions.csv', index=False, header=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.DataFrame(predictions_rounded).astype(int)\n",
    "res = pd.DataFrame(predictions_rounded)\n",
    "print(\"saving predictions...\")\n",
    "res.to_csv('data/predictions_sigmoid.csv', index=False, header=False)\n",
    "print(\"done\")\n",
    "\n",
    "res.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\"model\").mkdir(parents=True, exist_ok=True)  # create folder if necessary\n",
    "torch.save(model.state_dict(), \"model/params_6_layers\")\n",
    "# load: model.load_state_dict(torch.load(\"model/params\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-20844a55",
   "language": "python",
   "display_name": "PyCharm (intro-to-ml-21)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}