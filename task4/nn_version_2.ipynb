{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-1be61523501d>, line 67)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1be61523501d>\"\u001b[0;36m, line \u001b[0;32m67\u001b[0m\n\u001b[0;31m    nn.ReLU(inplace=True),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class FoodTriplets(Dataset):\n",
    "    \"\"\"\n",
    "    Class to load food triplets. Individual items consist of:\n",
    "     - x: concatenated image features of a triplet (ABC)\n",
    "     - y: corresponding label (1: B is more similar, 0: C is more similar, None: no label)\n",
    "    \"\"\"\n",
    "    def __init__(self, features_file, triplets_file, is_labelled_data=False):\n",
    "        print(\"initializing \" + str(triplets_file) + \" dataset...\")\n",
    "        self.img_features = pd.read_csv(\"data/\" + features_file, header=None, index_col=0)\n",
    "        self.triplets = pd.read_csv(\"data/\" + triplets_file, sep=\" \", header=None).to_numpy()\n",
    "        self.is_labelled_data = is_labelled_data\n",
    "        self.labels = None\n",
    "\n",
    "        if self.is_labelled_data:\n",
    "            # For each triplet ABC add a triplet ACB\n",
    "            # Also add corresponding labels\n",
    "            dim = self.triplets.shape\n",
    "            extended_triplets = np.zeros((2*dim[0], dim[1]), dtype=np.int32)\n",
    "            self.labels = np.zeros(2*dim[0], dtype=np.bool)\n",
    "            idx = 0\n",
    "            for triplet in self.triplets:\n",
    "                extended_triplets[idx, :] = triplet\n",
    "                extended_triplets[idx + 1, :] = [triplet[0], triplet[2], triplet[1]]\n",
    "                self.labels[idx] = 1  # label at idx+1 is already initialized to 0\n",
    "                idx += 2\n",
    "        print(\"done\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets[idx]\n",
    "        a, b, c = triplet[0], triplet[1], triplet[2]\n",
    "        a_features = self.img_features.loc[[a]].to_numpy(dtype=np.float32)\n",
    "        b_features = self.img_features.loc[[b]].to_numpy(dtype=np.float32)\n",
    "        c_features = self.img_features.loc[[c]].to_numpy(dtype=np.float32)\n",
    "        features = np.concatenate((a_features, b_features, c_features), axis=1)\n",
    "        label = 0  # dummy label\n",
    "        if self.is_labelled_data:\n",
    "            label = np.array([[self.labels[idx]]])\n",
    "        return {\"x\": features, \"y\": label}\n",
    "\n",
    "\n",
    "def get_simple_nn():\n",
    "    net = nn.Sequential(\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=12288, out_features=6144),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=6144, out_features=3072),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=3072, out_features=1500),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=1500, out_features=500),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=500, out_features=250),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.8, inplace=False),\n",
    "        nn.Linear(in_features=250, out_features=1)\n",
    "    )\n",
    "    return net\n",
    "\n",
    "# def get_first_try_nn():\n",
    "#     # input 3x1000\n",
    "#     # L1    1500\n",
    "#     # L2     750\n",
    "#     # L3\n",
    "#     # OUTPUT  1\n",
    "#     net = nn.Sequential(\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=12288, out_features=6144),\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=6144, out_features=3072),\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=3072, out_features=1500)\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=1500, out_features=500)\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=500, out_features=250)\n",
    "#         nn.ReLU(inplace=True),\n",
    "#         nn.Dropout(p=0.8, inplace=False),\n",
    "#         nn.Linear(in_features=250, out_features=1)\n",
    "#     )\n",
    "\n",
    "#     return net\n",
    "\n",
    "def timer(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return \"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours), int(minutes), seconds)\n",
    "\n",
    " \n",
    "torch.manual_seed(42)\n",
    "\n",
    "n_epochs = 2  # each epoch is one pass over the whole dataset\n",
    "batch_size = 4  # how many samples per training step (32,64,128)\n",
    "num_workers = 1  # how many CPU cores to use\n",
    "\n",
    "# Specify some file names\n",
    "img_features_file = \"train_image_features_vgg16bn.csv\"\n",
    "train_triplets_file = \"train_triplets.txt\" #\"train_triplets.txt\"\n",
    "test_triplets_file = \"test_triplets.txt\" #\"test_triplets.txt\"\n",
    "\n",
    "# initialize datasets and dataloaders\n",
    "train_data = FoodTriplets(img_features_file, train_triplets_file, is_labelled_data=True)\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_data = FoodTriplets(img_features_file, test_triplets_file, is_labelled_data=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=None, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs=30):\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    loss_function = nn.BCEWithLogitsLoss()  # combines sigmoid with binary cross entropy loss function\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    \n",
    "    n_batches = math.ceil(len(train_data) / batch_size)\n",
    " \n",
    "    print(f\"training started at {time.ctime()}\")\n",
    "    start_t = time.time()\n",
    "    print_frequency = 100\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "#         print(\"Epoch {}/{}\".format(epoch, num_epochs-1))\n",
    " \n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs = data[\"x\"].float()\n",
    "            labels = data[\"y\"].float()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()   \n",
    "\n",
    "            output = model(inputs)\n",
    "            \n",
    "            loss = loss_function(output, labels)\n",
    "            loss.backward() # Calculate gradients\n",
    "            optimizer.step() # Update weights\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % print_frequency == 0:\n",
    "#                 print(\"%d, %5d, loss: %.3f\" % (epoch, i, running_loss/100))\n",
    "                print(f\"Epoch: {epoch+1}/{n_epochs}, Batch: {i}/{n_batches}, loss: {running_loss/print_frequency}, \"\n",
    "                  f\"Time elapsed: {timer(start_t, time.time())}\")\n",
    "                running_loss = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_simple_nn()\n",
    "\n",
    "train_model(model=model,num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.to('cpu')\n",
    "\n",
    "# predict on test_data\n",
    "model_pred = nn.Sequential(model, nn.Softmax(dim=1))  # add softmax to get 1/0 output\n",
    "predictions = np.zeros(len(test_data))\n",
    "print(\"predicting on test_data...\")\n",
    "l_test = len(test_data)\n",
    "start_t = time.time()\n",
    "\n",
    "model_pred.to(device)\n",
    "\n",
    "for i, data in enumerate(test_dataloader, 0):\n",
    "    x = data[\"x\"].float()\n",
    "    \n",
    "    x = x.to(device)\n",
    "    predictions[i] = model_pred(x)\n",
    "#     predictions[i] = model(x)\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Predicted: {i}/{l_test}, Time elapsed: {timer(start_t, time.time())}\")\n",
    "        \n",
    "        \n",
    "# predictions_INT = pd.DataFrame(predictions).astype(int)\n",
    "predictions_DF = pd.DataFrame(predictions)\n",
    "predictions_rounded = predictions_DF.round(0)\n",
    "\n",
    "# print(\"saving predictions...\")\n",
    "# predictions_INT.to_csv('data/predictions.csv', index=False, header=False)\n",
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
